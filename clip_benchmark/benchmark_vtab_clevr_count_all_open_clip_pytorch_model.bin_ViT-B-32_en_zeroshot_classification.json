{"dataset": "vtab/clevr_count_all", "model": "ViT-B-32", "pretrained": "/mnt/shared/CLIP-ViT-B-32-laion2B-s34B-b79K/open_clip_pytorch_model.bin", "task": "zeroshot_classification", "metrics": {"acc1": 0.1534, "acc5": 0.696, "mean_per_class_recall": 0.15115857745388261}, "language": "en"}