{"dataset": "imagenet1k", "model": "ViT-B-32", "pretrained": "/mnt/shared/CLIP-ViT-B-32-laion2B-s34B-b79K/open_clip_pytorch_model.bin", "task": "zeroshot_classification", "metrics": {"acc1": 0.66546, "acc5": 0.89908, "mean_per_class_recall": 0.66558}, "language": "en"}